{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635eed74-087c-40d7-81c9-0ce8b3be2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa6ac1-7622-4162-bd65-8902163f276e",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab56644-be16-4968-b5a9-1c5e489d8cc7",
   "metadata": {},
   "source": [
    "<h4>Test Data genration Param</h4>\n",
    "<ls>\n",
    "    <li>n_samples: 2</li>\n",
    "    <li>n_channels: 12</li>\n",
    "    <li>n_timeStep: 24</li>\n",
    "    <li>encoding_len: 5</li>\n",
    "</ls>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b49fb5b-d3be-429a-9c75-7ad8e06891c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NxCxt\n",
    "def create_test_data(n_samples = 1, n_channels = 12, n_timeStep = 24, n_classes = 4):\n",
    "        \n",
    "        return torch.randn((n_samples, n_channels, n_timeStep)), torch.randn(n_samples, n_classes).argmax(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964cdd1d-0912-40de-97ed-1b8d516a2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test data shape: torch.Size([100, 12, 24]) & y_test shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_test_data(n_samples = 100)\n",
    "print(f\"X_test data shape: {X_test.shape} & y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936deeeb-f252-4f73-bf3e-45ab4cf68211",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2088af61-1cd4-45bf-8ee3-e72aedc0acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eeg_dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.class_id = y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "       return self.data[idx], self.class_id[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b109b96-d0ef-4dca-8065-2ccff49ab4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = eeg_dataset(X_test, y_test)\n",
    "train_dataloader = DataLoader(eeg_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fabe36-767b-4768-8465-728c50fab2bf",
   "metadata": {},
   "source": [
    "### Regional Level Information Extraction module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3af2fe-29e8-4bfa-80bc-612fa862a426",
   "metadata": {},
   "source": [
    "<h4> Testing Param </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b40d979-2499-448f-bd95-789cb6b6c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_hms = [1,3,6] #left_hemisphere\n",
    "right_hms = [0,2,5] #right_hemisphere\n",
    "middle_hms = [8, 9] #middle_hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdf9f34d-a052-4ade-9211-fd57c6e66bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regional_info_extraction(data, left_hms = left_hms, right_hms = right_hms, middle_hms = middle_hms):\n",
    "    comb_idx = list(zip(left_hms, right_hms))\n",
    "    hms_diff = []\n",
    "    print(data.shape)\n",
    "    data = data.reshape((data.shape[0], data.shape[1], data.shape[2], 1))\n",
    "\n",
    "    for (i, j) in comb_idx:\n",
    "        hms_diff.append(data[:, i, :, :] - data[:, j, :, :])\n",
    "\n",
    "    D = torch.cat(hms_diff, dim = 2)\n",
    "    S = data[:, middle_hms, : ,:].permute((0,2,1,3)).reshape((data.shape[0], data.shape[2], -1))\n",
    "    X = torch.cat((D,S), dim = 2)\n",
    "    print(f\"no. of iter: {len(comb_idx)}\")\n",
    "    print(f\"D shape: {D.shape} & D dimension {D.ndim}\")\n",
    "    print(f\"S shape: {S.shape} & S dimension {S.ndim}\")\n",
    "    print(f\"X shape: {X.shape} & X dimension {X.ndim}\")\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fdd96a7-5255-4252-bb45-c5e48f77b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = regional_info_extraction(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6331e5-31e0-4e77-aac8-0ca403bace3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8775fb7-4f8e-45fb-a9c6-964c370a4b83",
   "metadata": {},
   "source": [
    "### Feature Encoding module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a0de8-3eb8-48b5-94d5-718fe703261f",
   "metadata": {},
   "source": [
    "<h4>Testing Param</h4>\n",
    "<ls>\n",
    "    <li>input_size: 25</li>\n",
    "    <li>num_layer: 2</li>\n",
    "    <li>n_nodes(hidden_size): 5</li>\n",
    "    <li>LSTM Config: BiLSTM</li>\n",
    "</ls>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1863eb-3c02-4bfb-ba3f-2f06999f6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Encoding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size = 25,\n",
    "        out_features = 5,\n",
    "        num_layer = 2,\n",
    "        hidden_size = 5,\n",
    "        lstm_config = \"BiLSTM\"\n",
    "    ):\n",
    "        super().__init__(self)\n",
    "        self.Stack_BiLstm_layer = nn.LSTM(input_size = input_size,\n",
    "                                          hidden_size = hidden_size,\n",
    "                                          num_layers = num_layer,\n",
    "                                          bias = True,\n",
    "                                          batch_first = True,\n",
    "                                          dropout=0.0,\n",
    "                                          bidirectional = True if lstm_config == \"BiLSTM\" else False)\n",
    "        self.fcn_layer = nn.Linear(in_features = hidden_size, out_features = out_features, bias=True)\n",
    "        self.activation_layer = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stack_BiLSTM_layer(x)\n",
    "        x = self.fcn_layer(x[:, -1, :])\n",
    "        x = self.activation_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58ec29b-93b0-453e-9c56-f4501b8af1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Feature_Encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da15741-cecc-47e0-a873-36554722feff",
   "metadata": {},
   "source": [
    "### Classification Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "697ce415-064e-445d-a296-37bba0afb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "50e08012-f67b-4782-8b40-941e3c9409a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__(self)\n",
    "        self.fcn = nn.Linear(in_features = input_size, out_features = 40)\n",
    "    def forward(self, x):\n",
    "        return F.softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f45e0-a436-4eb6-86de-4a600a7fc97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "783ac79c-252f-449b-970c-7f0de30ae0a5",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2347c7d7-1df8-465f-8439-295686327fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch import optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb216eb2-7e1d-4be6-945f-04b08d053913",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.05 )\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a33828-f8cd-4d7c-8920-53fb444aceaa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f6f973-3e2e-4f69-9b0f-10e2a67d63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optim, loss_fn, device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for X,y in dataloader():\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        X = regional_info_extraction(X)\n",
    "        \n",
    "        yhat = model(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        yhat_classes = torch.argmax((torch.softmax(yhat, dim=1)), dim = 1)\n",
    "        train_acc += (yhat_classes == y).sum().item()/len(yhat)\n",
    "    train_acc = train_acc/len(dataloader)\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c48baf67-6ae0-41a0-a4e8-9d52daf8d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, dataloader, loss_fn, device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in dataloader():\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            X = regional_info_extraction(X)\n",
    "            \n",
    "            yhat = model(X)\n",
    "            loss = loss_fn(yhat, y)\n",
    "            test_loss += loss\n",
    "            \n",
    "            yhat_classes = torch.argmax((torch.softmax(yhat, dim=1)), dim = 1)\n",
    "            test_acc += (yhat_classes == y).sum().item()/len(yhat)\n",
    "    test_acc = test_acc/len(dataloader)\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "    return test_loss,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1221b3c5-bcd7-4a1b-8314-84d97616d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    epochs,\n",
    "    loss_fn,\n",
    "    device\n",
    "    ):\n",
    "    res_dict = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "      }\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, optimizer, loss_fn, device)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader,  loss_fn, device)\n",
    "        res_dict[\"train_loss\"].append(train_loss)\n",
    "        res_dict[\"train_acc\"].append(train_acc)\n",
    "        \n",
    "        res_dict[\"test_loss\"].append(test_loss)\n",
    "        res_dict[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(\n",
    "        f\"Epoch: {epoch+1} | \"\n",
    "        f\"train_loss: {train_loss:.4f} | \"\n",
    "        f\"train_acc: {train_acc:.4f} | \"\n",
    "        f\"test_loss: {test_loss:.4f} | \"\n",
    "        f\"test_acc: {test_acc:.4f} | \"\n",
    "        f\"lr {optimizer.param_groups[0]['lr']:.4f}\"\n",
    "        )\n",
    "    return res_dict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a839fb7-d876-4cb3-a7f4-f62a98aa5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb56c4c7-cb11-430c-a34c-7dfcfcbd242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data(5-95).npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f54b8a9-d849-471d-a3c0-638dbc6d340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Abhishek Rathore\\\\Desktop\\\\Paper & Code\\\\EEG_Imgcls_BiLSTM\\\\src\\\\data\\\\data(5-95).npy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(),'data', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f318c76-a38c-4309-be11-116e8d5a17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(file_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d8a99-1e76-4caf-9f7c-dcfa884075ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_dataset(Dataset):\n",
    "    def __init__(self, dir = 'data', file_name):\n",
    "        self.file_path = os.path.join(os.getcwd(),'data', file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a71f79-a365-4f09-b4d4-68aed296ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
